{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('master_dataset_clean.csv').drop([\"County\", \"State\", \"Unnamed: 0\",\"FIPS\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3121\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>live 2a1w1c</th>\n",
       "      <th>min 1a1c</th>\n",
       "      <th>pct_less_hs</th>\n",
       "      <th>pct_hs</th>\n",
       "      <th>pct_some_college</th>\n",
       "      <th>pct_college</th>\n",
       "      <th>crime_per_10k_x</th>\n",
       "      <th>unemployment_rate_2019</th>\n",
       "      <th>median_household_income_2019</th>\n",
       "      <th>Food</th>\n",
       "      <th>...</th>\n",
       "      <th>Civic</th>\n",
       "      <th>Other</th>\n",
       "      <th>Required annual income after taxes</th>\n",
       "      <th>Annual taxes</th>\n",
       "      <th>Required annual income before taxes</th>\n",
       "      <th>crime_per_10k_y</th>\n",
       "      <th>violent_crime_per_10k</th>\n",
       "      <th>hard_drugs_crime_per_10k</th>\n",
       "      <th>soft_drugs_crime_per_10k</th>\n",
       "      <th>commerce_crimes_per_10k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3121.000000</td>\n",
       "      <td>3121.000000</td>\n",
       "      <td>3121.000000</td>\n",
       "      <td>3121.000000</td>\n",
       "      <td>3121.000000</td>\n",
       "      <td>3121.000000</td>\n",
       "      <td>3121.000000</td>\n",
       "      <td>3121.000000</td>\n",
       "      <td>3121.000000</td>\n",
       "      <td>3121.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3121.000000</td>\n",
       "      <td>3121.000000</td>\n",
       "      <td>3121.000000</td>\n",
       "      <td>3121.000000</td>\n",
       "      <td>3121.000000</td>\n",
       "      <td>3121.000000</td>\n",
       "      <td>3121.000000</td>\n",
       "      <td>3121.000000</td>\n",
       "      <td>3121.000000</td>\n",
       "      <td>3121.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>27.035905</td>\n",
       "      <td>8.448635</td>\n",
       "      <td>13.061038</td>\n",
       "      <td>34.174015</td>\n",
       "      <td>30.826370</td>\n",
       "      <td>21.940308</td>\n",
       "      <td>213.517325</td>\n",
       "      <td>3.927587</td>\n",
       "      <td>55656.284524</td>\n",
       "      <td>7565.166293</td>\n",
       "      <td>...</td>\n",
       "      <td>3635.282602</td>\n",
       "      <td>5123.703941</td>\n",
       "      <td>45504.658122</td>\n",
       "      <td>10753.275873</td>\n",
       "      <td>56257.874079</td>\n",
       "      <td>213.517326</td>\n",
       "      <td>40.741543</td>\n",
       "      <td>8.742535</td>\n",
       "      <td>31.582034</td>\n",
       "      <td>27.082270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.146110</td>\n",
       "      <td>1.639746</td>\n",
       "      <td>6.258067</td>\n",
       "      <td>7.215851</td>\n",
       "      <td>5.200671</td>\n",
       "      <td>9.534227</td>\n",
       "      <td>195.699096</td>\n",
       "      <td>1.424564</td>\n",
       "      <td>14439.081331</td>\n",
       "      <td>517.016910</td>\n",
       "      <td>...</td>\n",
       "      <td>153.979634</td>\n",
       "      <td>117.596974</td>\n",
       "      <td>3086.739206</td>\n",
       "      <td>2364.840405</td>\n",
       "      <td>4488.883826</td>\n",
       "      <td>195.699039</td>\n",
       "      <td>39.094692</td>\n",
       "      <td>14.142338</td>\n",
       "      <td>45.326798</td>\n",
       "      <td>25.419047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>23.450000</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>24732.000000</td>\n",
       "      <td>7238.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3341.000000</td>\n",
       "      <td>4996.000000</td>\n",
       "      <td>42127.000000</td>\n",
       "      <td>6904.000000</td>\n",
       "      <td>49489.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25.800000</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>29.700000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>15.300000</td>\n",
       "      <td>84.610000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>46214.000000</td>\n",
       "      <td>7238.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3554.000000</td>\n",
       "      <td>5070.000000</td>\n",
       "      <td>43721.000000</td>\n",
       "      <td>9373.000000</td>\n",
       "      <td>53705.000000</td>\n",
       "      <td>84.605589</td>\n",
       "      <td>16.489165</td>\n",
       "      <td>0.565004</td>\n",
       "      <td>8.348988</td>\n",
       "      <td>7.850526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>26.590000</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>34.600000</td>\n",
       "      <td>30.800000</td>\n",
       "      <td>19.600000</td>\n",
       "      <td>177.400000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>53289.000000</td>\n",
       "      <td>7394.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3554.000000</td>\n",
       "      <td>5144.000000</td>\n",
       "      <td>44684.000000</td>\n",
       "      <td>10784.000000</td>\n",
       "      <td>55312.000000</td>\n",
       "      <td>177.402323</td>\n",
       "      <td>35.130573</td>\n",
       "      <td>4.196127</td>\n",
       "      <td>23.396531</td>\n",
       "      <td>21.669116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>27.560000</td>\n",
       "      <td>9.450000</td>\n",
       "      <td>16.700000</td>\n",
       "      <td>39.100000</td>\n",
       "      <td>34.200000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>290.450000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>7394.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3838.000000</td>\n",
       "      <td>5144.000000</td>\n",
       "      <td>46197.000000</td>\n",
       "      <td>12202.000000</td>\n",
       "      <td>57390.000000</td>\n",
       "      <td>290.448056</td>\n",
       "      <td>56.176651</td>\n",
       "      <td>11.053761</td>\n",
       "      <td>42.785566</td>\n",
       "      <td>40.073899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>49.450000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>73.600000</td>\n",
       "      <td>57.400000</td>\n",
       "      <td>60.600000</td>\n",
       "      <td>77.600000</td>\n",
       "      <td>2741.560000</td>\n",
       "      <td>20.900000</td>\n",
       "      <td>151806.000000</td>\n",
       "      <td>8639.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3838.000000</td>\n",
       "      <td>5514.000000</td>\n",
       "      <td>76454.000000</td>\n",
       "      <td>26406.000000</td>\n",
       "      <td>102860.000000</td>\n",
       "      <td>2741.562644</td>\n",
       "      <td>793.092910</td>\n",
       "      <td>212.765957</td>\n",
       "      <td>1210.780370</td>\n",
       "      <td>309.644670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       live 2a1w1c     min 1a1c  pct_less_hs       pct_hs  pct_some_college  \\\n",
       "count  3121.000000  3121.000000  3121.000000  3121.000000       3121.000000   \n",
       "mean     27.035905     8.448635    13.061038    34.174015         30.826370   \n",
       "std       2.146110     1.639746     6.258067     7.215851          5.200671   \n",
       "min      23.450000     7.250000     1.100000     7.300000          5.200000   \n",
       "25%      25.800000     7.250000     8.500000    29.700000         27.300000   \n",
       "50%      26.590000     7.250000    11.700000    34.600000         30.800000   \n",
       "75%      27.560000     9.450000    16.700000    39.100000         34.200000   \n",
       "max      49.450000    13.500000    73.600000    57.400000         60.600000   \n",
       "\n",
       "       pct_college  crime_per_10k_x  unemployment_rate_2019  \\\n",
       "count  3121.000000      3121.000000             3121.000000   \n",
       "mean     21.940308       213.517325                3.927587   \n",
       "std       9.534227       195.699096                1.424564   \n",
       "min       0.000000         0.000000                0.800000   \n",
       "25%      15.300000        84.610000                3.000000   \n",
       "50%      19.600000       177.400000                3.700000   \n",
       "75%      26.000000       290.450000                4.600000   \n",
       "max      77.600000      2741.560000               20.900000   \n",
       "\n",
       "       median_household_income_2019         Food  ...        Civic  \\\n",
       "count                   3121.000000  3121.000000  ...  3121.000000   \n",
       "mean                   55656.284524  7565.166293  ...  3635.282602   \n",
       "std                    14439.081331   517.016910  ...   153.979634   \n",
       "min                    24732.000000  7238.000000  ...  3341.000000   \n",
       "25%                    46214.000000  7238.000000  ...  3554.000000   \n",
       "50%                    53289.000000  7394.000000  ...  3554.000000   \n",
       "75%                    61878.000000  7394.000000  ...  3838.000000   \n",
       "max                   151806.000000  8639.000000  ...  3838.000000   \n",
       "\n",
       "             Other  Required annual income after taxes  Annual taxes  \\\n",
       "count  3121.000000                         3121.000000   3121.000000   \n",
       "mean   5123.703941                        45504.658122  10753.275873   \n",
       "std     117.596974                         3086.739206   2364.840405   \n",
       "min    4996.000000                        42127.000000   6904.000000   \n",
       "25%    5070.000000                        43721.000000   9373.000000   \n",
       "50%    5144.000000                        44684.000000  10784.000000   \n",
       "75%    5144.000000                        46197.000000  12202.000000   \n",
       "max    5514.000000                        76454.000000  26406.000000   \n",
       "\n",
       "       Required annual income before taxes  crime_per_10k_y  \\\n",
       "count                          3121.000000      3121.000000   \n",
       "mean                          56257.874079       213.517326   \n",
       "std                            4488.883826       195.699039   \n",
       "min                           49489.000000         0.000000   \n",
       "25%                           53705.000000        84.605589   \n",
       "50%                           55312.000000       177.402323   \n",
       "75%                           57390.000000       290.448056   \n",
       "max                          102860.000000      2741.562644   \n",
       "\n",
       "       violent_crime_per_10k  hard_drugs_crime_per_10k  \\\n",
       "count            3121.000000               3121.000000   \n",
       "mean               40.741543                  8.742535   \n",
       "std                39.094692                 14.142338   \n",
       "min                 0.000000                  0.000000   \n",
       "25%                16.489165                  0.565004   \n",
       "50%                35.130573                  4.196127   \n",
       "75%                56.176651                 11.053761   \n",
       "max               793.092910                212.765957   \n",
       "\n",
       "       soft_drugs_crime_per_10k  commerce_crimes_per_10k  \n",
       "count               3121.000000              3121.000000  \n",
       "mean                  31.582034                27.082270  \n",
       "std                   45.326798                25.419047  \n",
       "min                    0.000000                 0.000000  \n",
       "25%                    8.348988                 7.850526  \n",
       "50%                   23.396531                21.669116  \n",
       "75%                   42.785566                40.073899  \n",
       "max                 1210.780370               309.644670  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "#drop all upper bound outliers\n",
    "# df = df[(np.abs(stats.zscore(df)) < 3).all(axis=1)]\n",
    "#drop all lower bound outliers\n",
    "# df = df[(np.abs(stats.zscore(df)) > -3).all(axis=1)]\n",
    "#drop zero row values\n",
    "# df = df.loc[(df!=0).any(axis=1)]\n",
    "print(len(df))\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['crime_per_10k_x','crime_per_10k_y','violent_crime_per_10k', 'hard_drugs_crime_per_10k','soft_drugs_crime_per_10k', 'commerce_crimes_per_10k'],axis=1)\n",
    "y = df['crime_per_10k_y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_35 (Dense)             (None, 10)                180       \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 100)               1100      \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,381\n",
      "Trainable params: 1,381\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=10, activation=\"linear\", input_dim=X.shape[1]))\n",
    "\n",
    "# Second hidden layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=100, activation=\"linear\"))\n",
    "\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "74/74 [==============================] - 0s 779us/step - loss: -328.7967 - accuracy: 0.0286\n",
      "Epoch 2/50\n",
      "74/74 [==============================] - 0s 806us/step - loss: -1085.9148 - accuracy: 0.0197\n",
      "Epoch 3/50\n",
      "74/74 [==============================] - 0s 683us/step - loss: -1358.7051 - accuracy: 0.0179\n",
      "Epoch 4/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: -1481.0698 - accuracy: 0.0171\n",
      "Epoch 5/50\n",
      "74/74 [==============================] - 0s 888us/step - loss: -1781.3394 - accuracy: 0.0137\n",
      "Epoch 6/50\n",
      "74/74 [==============================] - 0s 724us/step - loss: -2419.4658 - accuracy: 0.0056\n",
      "Epoch 7/50\n",
      "74/74 [==============================] - 0s 642us/step - loss: -3048.1531 - accuracy: 0.0030\n",
      "Epoch 8/50\n",
      "74/74 [==============================] - 0s 587us/step - loss: -3193.1289 - accuracy: 8.5470e-04\n",
      "Epoch 9/50\n",
      "74/74 [==============================] - 0s 656us/step - loss: -3215.2437 - accuracy: 8.5470e-04\n",
      "Epoch 10/50\n",
      "74/74 [==============================] - 0s 683us/step - loss: -3240.4429 - accuracy: 8.5470e-04\n",
      "Epoch 11/50\n",
      "74/74 [==============================] - 0s 820us/step - loss: -3240.5249 - accuracy: 8.5470e-04\n",
      "Epoch 12/50\n",
      "74/74 [==============================] - 0s 806us/step - loss: -3241.3337 - accuracy: 8.5470e-04\n",
      "Epoch 13/50\n",
      "74/74 [==============================] - 0s 820us/step - loss: -3239.3169 - accuracy: 8.5470e-04\n",
      "Epoch 14/50\n",
      "74/74 [==============================] - 0s 888us/step - loss: -3230.4333 - accuracy: 8.5470e-04\n",
      "Epoch 15/50\n",
      "74/74 [==============================] - 0s 833us/step - loss: -3244.8059 - accuracy: 8.5470e-04\n",
      "Epoch 16/50\n",
      "74/74 [==============================] - 0s 847us/step - loss: -3244.8110 - accuracy: 8.5470e-04\n",
      "Epoch 17/50\n",
      "74/74 [==============================] - 0s 820us/step - loss: -3244.8176 - accuracy: 8.5470e-04\n",
      "Epoch 18/50\n",
      "74/74 [==============================] - 0s 738us/step - loss: -3244.8247 - accuracy: 4.2735e-04\n",
      "Epoch 19/50\n",
      "74/74 [==============================] - 0s 697us/step - loss: -3244.8318 - accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "74/74 [==============================] - 0s 765us/step - loss: -3244.8413 - accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "74/74 [==============================] - 0s 833us/step - loss: -3244.8518 - accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "74/74 [==============================] - 0s 629us/step - loss: -3244.8660 - accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "74/74 [==============================] - 0s 669us/step - loss: -3244.8838 - accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "74/74 [==============================] - 0s 738us/step - loss: -3244.9104 - accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "74/74 [==============================] - 0s 669us/step - loss: -3244.9590 - accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "74/74 [==============================] - 0s 724us/step - loss: -3245.4309 - accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "74/74 [==============================] - 0s 847us/step - loss: -3245.8291 - accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "74/74 [==============================] - 0s 628us/step - loss: -3245.8289 - accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "74/74 [==============================] - 0s 847us/step - loss: -3245.8286 - accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "74/74 [==============================] - 0s 765us/step - loss: -3245.8291 - accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "74/74 [==============================] - 0s 806us/step - loss: -3245.8279 - accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "74/74 [==============================] - 0s 792us/step - loss: -3245.8284 - accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "74/74 [==============================] - 0s 847us/step - loss: -3245.8289 - accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "74/74 [==============================] - 0s 710us/step - loss: -3245.8291 - accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "74/74 [==============================] - 0s 669us/step - loss: -3245.8289 - accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "74/74 [==============================] - 0s 751us/step - loss: -3245.8281 - accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "74/74 [==============================] - 0s 779us/step - loss: -3245.8281 - accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "74/74 [==============================] - 0s 738us/step - loss: -3245.8281 - accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "74/74 [==============================] - 0s 615us/step - loss: -3245.8286 - accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "74/74 [==============================] - 0s 615us/step - loss: -3245.8281 - accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "74/74 [==============================] - 0s 710us/step - loss: -3245.8289 - accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "74/74 [==============================] - 0s 792us/step - loss: -3245.8284 - accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "74/74 [==============================] - 0s 724us/step - loss: -3245.8293 - accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "74/74 [==============================] - 0s 710us/step - loss: -3245.8291 - accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "74/74 [==============================] - 0s 683us/step - loss: -3245.8289 - accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "74/74 [==============================] - 0s 628us/step - loss: -3245.8289 - accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "74/74 [==============================] - 0s 683us/step - loss: -3245.8286 - accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "74/74 [==============================] - 0s 779us/step - loss: -3245.8289 - accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "74/74 [==============================] - 0s 765us/step - loss: -3245.8284 - accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "74/74 [==============================] - 0s 1ms/step - loss: -3245.8286 - accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=50)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3b32922ae442944bae51de5c420d7545d4126864cdc0e7cb358b7d9924f39d3e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('PythonData': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
