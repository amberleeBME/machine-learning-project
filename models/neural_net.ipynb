{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('master_dataset_clean.csv').drop([\"County\", \"State\", \"Unnamed: 0\",\"FIPS\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3121\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>live 2a1w1c</th>\n",
       "      <th>min 1a1c</th>\n",
       "      <th>pct_less_hs</th>\n",
       "      <th>pct_hs</th>\n",
       "      <th>pct_some_college</th>\n",
       "      <th>pct_college</th>\n",
       "      <th>crime_per_10k_x</th>\n",
       "      <th>unemployment_rate_2019</th>\n",
       "      <th>median_household_income_2019</th>\n",
       "      <th>Food</th>\n",
       "      <th>...</th>\n",
       "      <th>Civic</th>\n",
       "      <th>Other</th>\n",
       "      <th>Required annual income after taxes</th>\n",
       "      <th>Annual taxes</th>\n",
       "      <th>Required annual income before taxes</th>\n",
       "      <th>crime_per_10k_y</th>\n",
       "      <th>violent_crime_per_10k</th>\n",
       "      <th>hard_drugs_crime_per_10k</th>\n",
       "      <th>soft_drugs_crime_per_10k</th>\n",
       "      <th>commerce_crimes_per_10k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3121.000000</td>\n",
       "      <td>3121.000000</td>\n",
       "      <td>3121.000000</td>\n",
       "      <td>3121.000000</td>\n",
       "      <td>3121.000000</td>\n",
       "      <td>3121.000000</td>\n",
       "      <td>3121.000000</td>\n",
       "      <td>3121.000000</td>\n",
       "      <td>3121.000000</td>\n",
       "      <td>3121.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3121.000000</td>\n",
       "      <td>3121.000000</td>\n",
       "      <td>3121.000000</td>\n",
       "      <td>3121.000000</td>\n",
       "      <td>3121.000000</td>\n",
       "      <td>3121.000000</td>\n",
       "      <td>3121.000000</td>\n",
       "      <td>3121.000000</td>\n",
       "      <td>3121.000000</td>\n",
       "      <td>3121.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>27.035905</td>\n",
       "      <td>8.448635</td>\n",
       "      <td>13.061038</td>\n",
       "      <td>34.174015</td>\n",
       "      <td>30.826370</td>\n",
       "      <td>21.940308</td>\n",
       "      <td>213.517325</td>\n",
       "      <td>3.927587</td>\n",
       "      <td>55656.284524</td>\n",
       "      <td>7565.166293</td>\n",
       "      <td>...</td>\n",
       "      <td>3635.282602</td>\n",
       "      <td>5123.703941</td>\n",
       "      <td>45504.658122</td>\n",
       "      <td>10753.275873</td>\n",
       "      <td>56257.874079</td>\n",
       "      <td>213.517326</td>\n",
       "      <td>40.741543</td>\n",
       "      <td>8.742535</td>\n",
       "      <td>31.582034</td>\n",
       "      <td>27.082270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.146110</td>\n",
       "      <td>1.639746</td>\n",
       "      <td>6.258067</td>\n",
       "      <td>7.215851</td>\n",
       "      <td>5.200671</td>\n",
       "      <td>9.534227</td>\n",
       "      <td>195.699096</td>\n",
       "      <td>1.424564</td>\n",
       "      <td>14439.081331</td>\n",
       "      <td>517.016910</td>\n",
       "      <td>...</td>\n",
       "      <td>153.979634</td>\n",
       "      <td>117.596974</td>\n",
       "      <td>3086.739206</td>\n",
       "      <td>2364.840405</td>\n",
       "      <td>4488.883826</td>\n",
       "      <td>195.699039</td>\n",
       "      <td>39.094692</td>\n",
       "      <td>14.142338</td>\n",
       "      <td>45.326798</td>\n",
       "      <td>25.419047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>23.450000</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>24732.000000</td>\n",
       "      <td>7238.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3341.000000</td>\n",
       "      <td>4996.000000</td>\n",
       "      <td>42127.000000</td>\n",
       "      <td>6904.000000</td>\n",
       "      <td>49489.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25.800000</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>29.700000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>15.300000</td>\n",
       "      <td>84.610000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>46214.000000</td>\n",
       "      <td>7238.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3554.000000</td>\n",
       "      <td>5070.000000</td>\n",
       "      <td>43721.000000</td>\n",
       "      <td>9373.000000</td>\n",
       "      <td>53705.000000</td>\n",
       "      <td>84.605589</td>\n",
       "      <td>16.489165</td>\n",
       "      <td>0.565004</td>\n",
       "      <td>8.348988</td>\n",
       "      <td>7.850526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>26.590000</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>34.600000</td>\n",
       "      <td>30.800000</td>\n",
       "      <td>19.600000</td>\n",
       "      <td>177.400000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>53289.000000</td>\n",
       "      <td>7394.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3554.000000</td>\n",
       "      <td>5144.000000</td>\n",
       "      <td>44684.000000</td>\n",
       "      <td>10784.000000</td>\n",
       "      <td>55312.000000</td>\n",
       "      <td>177.402323</td>\n",
       "      <td>35.130573</td>\n",
       "      <td>4.196127</td>\n",
       "      <td>23.396531</td>\n",
       "      <td>21.669116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>27.560000</td>\n",
       "      <td>9.450000</td>\n",
       "      <td>16.700000</td>\n",
       "      <td>39.100000</td>\n",
       "      <td>34.200000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>290.450000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>7394.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3838.000000</td>\n",
       "      <td>5144.000000</td>\n",
       "      <td>46197.000000</td>\n",
       "      <td>12202.000000</td>\n",
       "      <td>57390.000000</td>\n",
       "      <td>290.448056</td>\n",
       "      <td>56.176651</td>\n",
       "      <td>11.053761</td>\n",
       "      <td>42.785566</td>\n",
       "      <td>40.073899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>49.450000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>73.600000</td>\n",
       "      <td>57.400000</td>\n",
       "      <td>60.600000</td>\n",
       "      <td>77.600000</td>\n",
       "      <td>2741.560000</td>\n",
       "      <td>20.900000</td>\n",
       "      <td>151806.000000</td>\n",
       "      <td>8639.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3838.000000</td>\n",
       "      <td>5514.000000</td>\n",
       "      <td>76454.000000</td>\n",
       "      <td>26406.000000</td>\n",
       "      <td>102860.000000</td>\n",
       "      <td>2741.562644</td>\n",
       "      <td>793.092910</td>\n",
       "      <td>212.765957</td>\n",
       "      <td>1210.780370</td>\n",
       "      <td>309.644670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       live 2a1w1c     min 1a1c  pct_less_hs       pct_hs  pct_some_college  \\\n",
       "count  3121.000000  3121.000000  3121.000000  3121.000000       3121.000000   \n",
       "mean     27.035905     8.448635    13.061038    34.174015         30.826370   \n",
       "std       2.146110     1.639746     6.258067     7.215851          5.200671   \n",
       "min      23.450000     7.250000     1.100000     7.300000          5.200000   \n",
       "25%      25.800000     7.250000     8.500000    29.700000         27.300000   \n",
       "50%      26.590000     7.250000    11.700000    34.600000         30.800000   \n",
       "75%      27.560000     9.450000    16.700000    39.100000         34.200000   \n",
       "max      49.450000    13.500000    73.600000    57.400000         60.600000   \n",
       "\n",
       "       pct_college  crime_per_10k_x  unemployment_rate_2019  \\\n",
       "count  3121.000000      3121.000000             3121.000000   \n",
       "mean     21.940308       213.517325                3.927587   \n",
       "std       9.534227       195.699096                1.424564   \n",
       "min       0.000000         0.000000                0.800000   \n",
       "25%      15.300000        84.610000                3.000000   \n",
       "50%      19.600000       177.400000                3.700000   \n",
       "75%      26.000000       290.450000                4.600000   \n",
       "max      77.600000      2741.560000               20.900000   \n",
       "\n",
       "       median_household_income_2019         Food  ...        Civic  \\\n",
       "count                   3121.000000  3121.000000  ...  3121.000000   \n",
       "mean                   55656.284524  7565.166293  ...  3635.282602   \n",
       "std                    14439.081331   517.016910  ...   153.979634   \n",
       "min                    24732.000000  7238.000000  ...  3341.000000   \n",
       "25%                    46214.000000  7238.000000  ...  3554.000000   \n",
       "50%                    53289.000000  7394.000000  ...  3554.000000   \n",
       "75%                    61878.000000  7394.000000  ...  3838.000000   \n",
       "max                   151806.000000  8639.000000  ...  3838.000000   \n",
       "\n",
       "             Other  Required annual income after taxes  Annual taxes  \\\n",
       "count  3121.000000                         3121.000000   3121.000000   \n",
       "mean   5123.703941                        45504.658122  10753.275873   \n",
       "std     117.596974                         3086.739206   2364.840405   \n",
       "min    4996.000000                        42127.000000   6904.000000   \n",
       "25%    5070.000000                        43721.000000   9373.000000   \n",
       "50%    5144.000000                        44684.000000  10784.000000   \n",
       "75%    5144.000000                        46197.000000  12202.000000   \n",
       "max    5514.000000                        76454.000000  26406.000000   \n",
       "\n",
       "       Required annual income before taxes  crime_per_10k_y  \\\n",
       "count                          3121.000000      3121.000000   \n",
       "mean                          56257.874079       213.517326   \n",
       "std                            4488.883826       195.699039   \n",
       "min                           49489.000000         0.000000   \n",
       "25%                           53705.000000        84.605589   \n",
       "50%                           55312.000000       177.402323   \n",
       "75%                           57390.000000       290.448056   \n",
       "max                          102860.000000      2741.562644   \n",
       "\n",
       "       violent_crime_per_10k  hard_drugs_crime_per_10k  \\\n",
       "count            3121.000000               3121.000000   \n",
       "mean               40.741543                  8.742535   \n",
       "std                39.094692                 14.142338   \n",
       "min                 0.000000                  0.000000   \n",
       "25%                16.489165                  0.565004   \n",
       "50%                35.130573                  4.196127   \n",
       "75%                56.176651                 11.053761   \n",
       "max               793.092910                212.765957   \n",
       "\n",
       "       soft_drugs_crime_per_10k  commerce_crimes_per_10k  \n",
       "count               3121.000000              3121.000000  \n",
       "mean                  31.582034                27.082270  \n",
       "std                   45.326798                25.419047  \n",
       "min                    0.000000                 0.000000  \n",
       "25%                    8.348988                 7.850526  \n",
       "50%                   23.396531                21.669116  \n",
       "75%                   42.785566                40.073899  \n",
       "max                 1210.780370               309.644670  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "#drop all upper bound outliers\n",
    "# df = df[(np.abs(stats.zscore(df)) < 3).all(axis=1)]\n",
    "#drop all lower bound outliers\n",
    "# df = df[(np.abs(stats.zscore(df)) > -3).all(axis=1)]\n",
    "#drop zero row values\n",
    "# df = df.loc[(df!=0).any(axis=1)]\n",
    "print(len(df))\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['crime_per_10k_x','crime_per_10k_y','violent_crime_per_10k', 'hard_drugs_crime_per_10k','soft_drugs_crime_per_10k', 'commerce_crimes_per_10k'],axis=1)\n",
    "y = df['crime_per_10k_y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import PReLU\n",
    "from keras.layers import ELU\n",
    "\n",
    "from keras.initializers import variance_scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "74/74 [==============================] - 0s 779us/step - loss: 405.2083 - accuracy: 0.0774\n",
      "Epoch 2/10\n",
      "74/74 [==============================] - 0s 697us/step - loss: 56.6534 - accuracy: 0.0726\n",
      "Epoch 3/10\n",
      "74/74 [==============================] - 0s 1ms/step - loss: -27.2583 - accuracy: 0.0671\n",
      "Epoch 4/10\n",
      "74/74 [==============================] - 0s 1ms/step - loss: -154.2395 - accuracy: 0.0624\n",
      "Epoch 5/10\n",
      "74/74 [==============================] - 0s 1ms/step - loss: -316.9617 - accuracy: 0.0568\n",
      "Epoch 6/10\n",
      "74/74 [==============================] - 0s 1ms/step - loss: -598.6624 - accuracy: 0.0462\n",
      "Epoch 7/10\n",
      "74/74 [==============================] - 0s 1ms/step - loss: -626.3538 - accuracy: 0.0440\n",
      "Epoch 8/10\n",
      "74/74 [==============================] - 0s 1ms/step - loss: -660.3611 - accuracy: 0.0423\n",
      "Epoch 9/10\n",
      "74/74 [==============================] - 0s 1ms/step - loss: -700.2460 - accuracy: 0.0419\n",
      "Epoch 10/10\n",
      "74/74 [==============================] - 0s 1ms/step - loss: -734.6098 - accuracy: 0.0406\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "he_avg_init = variance_scaling(scale=2.0, mode='fan_in', distribution='uniform')\n",
    "# First hidden layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=2, activation=\"linear\", input_dim=X.shape[1], kernel_initializer=\"lecun_normal\"))\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"selu\", kernel_initializer=\"lecun_normal\"))\n",
    "# nn_model.add(LeakyReLU(alpha=0.2))\n",
    ")\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"selu\", kernel_initializer=\"lecun_normal\"))\n",
    "nn_model.add(LeakyReLU(alpha=0.2))\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"selu\", kernel_initializer=\"lecun_normal\"))\n",
    "nn_model.add(LeakyReLU(alpha=0.2))\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"selu\", kernel_initializer=\"lecun_normal\"))\n",
    "nn_model.add(LeakyReLU(alpha=0.2))\n",
    "# nn_model.add(PReLU())\n",
    "\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a method that creates a new Sequential model with hyperparameter options\n",
    "def create_model(hp):\n",
    "    nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "    # Allow kerastuner to decide which activation function to use in hidden layers\n",
    "    activation = hp.Choice('activation',['relu','linear',\"selu\", \"gelu\"])\n",
    "    \n",
    "    # Allow kerastuner to decide number of neurons in first layer\n",
    "    nn_model.add(tf.keras.layers.Dense(units=hp.Int('first_units',\n",
    "        min_value=1,\n",
    "        max_value=30,\n",
    "        step=5), activation=activation, input_dim=X.shape[1]))\n",
    "\n",
    "    # Allow kerastuner to decide number of hidden layers and neurons in hidden layers\n",
    "    for i in range(hp.Int('num_layers', 1, 10)):\n",
    "        nn_model.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
    "            min_value=1,\n",
    "            max_value=30,\n",
    "            step=5),\n",
    "            activation=activation))\n",
    "    \n",
    "    nn_model.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "    # Compile the model\n",
    "    nn_model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
    "    \n",
    "    return nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project C:\\Users\\steve\\Desktop\\untitled_project\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from C:\\Users\\steve\\Desktop\\untitled_project\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "# Import the kerastuner library\n",
    "import kerastuner as kt\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=20,\n",
    "    hyperband_iterations=2,\n",
    "    directory=os.path.normpath('C:/Users/steve/Desktop'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 12 Complete [00h 00m 02s]\n",
      "val_accuracy: 0.09731113910675049\n",
      "\n",
      "Best val_accuracy So Far: 0.09731113910675049\n",
      "Total elapsed time: 00h 00m 27s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# Run the kerastuner search for best hyperparameters\n",
    "tuner.search(X_train_scaled,y_train,epochs=20,validation_data=(X_test_scaled,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'gelu',\n",
       " 'first_units': 11,\n",
       " 'num_layers': 7,\n",
       " 'units_0': 1,\n",
       " 'units_1': 21,\n",
       " 'units_2': 11,\n",
       " 'units_3': 11,\n",
       " 'units_4': 16,\n",
       " 'units_5': 11,\n",
       " 'units_6': 6,\n",
       " 'units_7': 6,\n",
       " 'units_8': 6,\n",
       " 'units_9': 16,\n",
       " 'tuner/epochs': 3,\n",
       " 'tuner/initial_epoch': 0,\n",
       " 'tuner/bracket': 2,\n",
       " 'tuner/round': 0}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get second best model hyperparameters\n",
    "second_hyper = tuner.get_best_hyperparameters(2)[0]\n",
    "second_hyper.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "('Keyword argument not understood:', 'init')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20456/786133895.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m\"elu\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"he_normal\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m\"elu\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernal_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"he_normal\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\keras\\layers\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m                \u001b[0mbias_constraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m                **kwargs):\n\u001b[1;32m-> 1147\u001b[1;33m     super(Dense, self).__init__(\n\u001b[0m\u001b[0;32m   1148\u001b[0m         activity_regularizer=activity_regularizer, **kwargs)\n\u001b[0;32m   1149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, trainable, name, dtype, dynamic, **kwargs)\u001b[0m\n\u001b[0;32m    321\u001b[0m     }\n\u001b[0;32m    322\u001b[0m     \u001b[1;31m# Validate optional keyword arguments.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m     \u001b[0mgeneric_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[1;31m# Mutable properties\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mvalidate_kwargs\u001b[1;34m(kwargs, allowed_kwargs, error_message)\u001b[0m\n\u001b[0;32m   1141\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1143\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwarg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: ('Keyword argument not understood:', 'init')"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=X_train_scaled.shape),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(300, activation= \"elu\", init=\"he_normal\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(100, activation= \"elu\", kernal_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(10, activation = \"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3b32922ae442944bae51de5c420d7545d4126864cdc0e7cb358b7d9924f39d3e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('PythonData': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
